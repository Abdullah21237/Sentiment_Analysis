{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d28e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeee7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data into a DataFrame\n",
    "encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df = pd.read_csv('Path Of Your Data Set', encoding=encoding)\n",
    "        # If reading succeeds, break out of the loop\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read with encoding {encoding}\")\n",
    "\n",
    "# Now df contains your DataFrame with the successfully decoded data\n",
    "\n",
    "# Display a few values from the original data\n",
    "print(\"Original Data Sample:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the column containing text data\n",
    "message_column = 'Column Name Contain Text Data'\n",
    "\n",
    "# Check and convert non-string elements to strings\n",
    "df[message_column] = df[message_column].astype(str)\n",
    "\n",
    "# Lowercasing and removing special characters\n",
    "df[message_column] = df[message_column].str.lower()\n",
    "df[message_column] = df[message_column].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x))\n",
    "# Display a few values after preprocessing\n",
    "print(\"\\nData After Preprocessing:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8689b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable y\n",
    "y_encoded = label_encoder.fit_transform(df['Column Name Contain Sentiment'])\n",
    "# Display a few values of y (encoded)\n",
    "print(\"\\nEncoded Target Variable (y):\")\n",
    "print(y_encoded[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3918d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=10000)  # Adjust num_words as needed\n",
    "tokenizer.fit_on_texts(df[message_column])\n",
    "# Convert text to sequences\n",
    "X_sequences = tokenizer.texts_to_sequences(df[message_column])\n",
    "# Display a few Sequences\n",
    "print(\"\\nDispla few values of sequences:\")\n",
    "print(X_sequences[:5])\n",
    "# Pad sequences to a fixed length (adjust maxlen as needed)\n",
    "X_padded = pad_sequences(X_sequences, maxlen=100)  # maxlen is the maximum sequence length\n",
    "# Display a few Pad Sequences\n",
    "print(\"\\nDisplay few values of pad sequences:\")\n",
    "print(X_padded[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357dc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)\n",
    "# Display a few values of X_train\n",
    "print(\"\\nFew Values Of X_train :\")\n",
    "print(X_train[:5])\n",
    "# Display a few values of X_test\n",
    "print(\"\\nFew Values Of X_test :\")\n",
    "print(X_test[:5])\n",
    "# Display a few values of y_train\n",
    "print(\"\\nFew Values Of y_train :\")\n",
    "print(y_train[:5])\n",
    "# Display a few values of y_test\n",
    "print(\"\\nFew Values Of y_test:\")\n",
    "print(y_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9db6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# Build a more complex RNN model with LSTM layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "model.add(LSTM(units=128, return_sequences=True))  # Return sequences for deeper layers\n",
    "model.add(LSTM(units=64))  # You can add more LSTM layers for better performance\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Compile the model with a lower learning rate and dropout for regularization\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with more epochs and a larger batch size\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e79fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

Support Vector Machine (SVM) Text Classification Model Documentation

Table of Contents

1. Introduction
    - Background Information
      - This text classification project aims to develop a machine learning model capable of analyzing and categorizing text messages based on their sentiment. 
	Sentiment analysis is crucial for understanding customer feedback, social media sentiment, and other applications.
    - Objective
      - The main objective of this project is to build an accurate sentiment analysis model using Support Vector Machine (SVM) that can classify text messages into predefined sentiment categories (e.g., positive, negative, neutral).
    - Dataset Description
      - The dataset used in this project consists of text messages along with their corresponding sentiment labels. 
	It was collected from [Kaggle] and contains [27482] records. The dataset includes the following columns:
        - `Selected_text`: Textual content of the message.
        - `sentiment`: The sentiment label associated with each message.

2. Data Preprocessing
    - Data Loading
      - The dataset was loaded using the Pandas library, attempting different encodings (UTF-8, Latin-1, ISO-8859-1, CP1252) to ensure successful loading without encoding issues.
    - Data Cleaning
      - Data cleaning involved checking for missing values and duplicate records. No missing values were found, and duplicates were removed to ensure data quality.
    - Text Preprocessing
      - Text preprocessing steps included converting all text to lowercase to ensure consistent casing and removing special characters and punctuation to focus on the text's content.
    - Encoding the Target Variable
      - The target variable, 'sentiment,' was encoded using the LabelEncoder from Scikit-Learn to convert categorical sentiment labels into numerical format for model training.

3. Feature Engineering
    - TF-IDF Vectorization
      - Term Frequency-Inverse Document Frequency (TF-IDF) vectorization was applied to convert the text data into numerical features. 
	A maximum of 1000 features were selected to represent the text messages.
    - Feature Selection (if applicable)
      - No specific feature selection was performed in this project. 
	All TF-IDF features were used for training the SVM model.

4. Model Building
    - Choosing SVM Algorithm
      - The Support Vector Machine (SVM) algorithm was selected for text classification due to its effectiveness in handling high-dimensional data and its ability to find optimal hyperplanes for separating different sentiment classes. 
	A rbf kernel was chosen as a starting point.
    - Model Training
      - The dataset was split into training and testing sets (80% training, 20% testing) to train and evaluate the SVM model. 
	The SVM model was trained using the Scikit-Learn library with the chosen kernel.

5. Results
    - Model Performance Metrics
      - The model's performance was evaluated using various metrics, including accuracy, precision, recall, and F1-score. 
	These metrics provide insights into the model's ability to correctly classify text messages into sentiment categories.
Accuracy: 0.8240858650172822

Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.78      0.79      1562
           1       0.79      0.91      0.84      2230
           2       0.92      0.75      0.83      1705

    accuracy                           0.82      5497
   macro avg       0.84      0.81      0.82      5497
weighted avg       0.83      0.82      0.82      5497
0 = Negative
1 = Neutral
2 = Positive

6. Conclusion
    - Summary of Findings
      - The SVM text classification model achieved an accuracy of [0.82]. 
	It performed well in categorizing text messages into sentiment classes. 
	However, further analysis is needed to identify potential model limitations.
    - Model Limitations
      - Model limitations include potential biases in the training data and areas where the model may not perform well, such as handling sarcasm or subtle nuances in text.
    - Future Improvements
      - Future work may involve experimenting with different kernels (e.g., radial basis function) to improve model performance, collecting more diverse training data, and enhancing preprocessing steps to address specific text challenges.